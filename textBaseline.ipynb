{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '../input/'\n",
    "DATA_PATH = '../shopee-product-matching/'\n",
    "\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2, matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import gc\n",
    "\n",
    "# import cudf, cuml, cupy\n",
    "# from cuml.feature_extraction.text import TfidfVectorizer\n",
    "# from cuml.neighbors import NearestNeighbors\n",
    "\n",
    "def getMetric(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this submission notebook will compute CV score, but commit notebook will not\n",
      "train shape is (34250, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>../shopee-product-matching/train_images/0000a6...</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>[train_129225211, train_2278313361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>../shopee-product-matching/train_images/000397...</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>[train_3386243561, train_3423213080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>../shopee-product-matching/train_images/000a19...</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>[train_2288590299, train_3803689425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>../shopee-product-matching/train_images/00117e...</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>[train_2406599165, train_3342059966]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>../shopee-product-matching/train_images/00136d...</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>[train_3369186413, train_921438619]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                              image   \n",
       "0   train_129225211  ../shopee-product-matching/train_images/0000a6...  \\\n",
       "1  train_3386243561  ../shopee-product-matching/train_images/000397...   \n",
       "2  train_2288590299  ../shopee-product-matching/train_images/000a19...   \n",
       "3  train_2406599165  ../shopee-product-matching/train_images/00117e...   \n",
       "4  train_3369186413  ../shopee-product-matching/train_images/00136d...   \n",
       "\n",
       "        image_phash                                              title   \n",
       "0  94974f937d4c2433                          Paper Bag Victoria Secret  \\\n",
       "1  af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n",
       "2  b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3  8514fc58eafea283  Daster Batik Lengan pendek - Motif Acak / Camp...   \n",
       "4  a6f319f924ad708c                  Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "\n",
       "   label_group                                target  \n",
       "0    249114794   [train_129225211, train_2278313361]  \n",
       "1   2937985045  [train_3386243561, train_3423213080]  \n",
       "2   2395904891  [train_2288590299, train_3803689425]  \n",
       "3   4093212188  [train_2406599165, train_3342059966]  \n",
       "4   3648931069   [train_3369186413, train_921438619]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMPUTE_CV = True\n",
    "\n",
    "test = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "if len(test)>3: COMPUTE_CV = False\n",
    "else: print('this submission notebook will compute CV score, but commit notebook will not')\n",
    "\n",
    "# COMPUTE_CV = False\n",
    "\n",
    "if COMPUTE_CV:\n",
    "    train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "    train['image'] = DATA_PATH + 'train_images/' + train['image']\n",
    "    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "    train['target'] = train.label_group.map(tmp)\n",
    "    # train_gf = cudf.read_csv(DATA_PATH + 'train.csv')\n",
    "else:\n",
    "    train = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "    train['image'] = DATA_PATH + 'test_images/' + train['image']\n",
    "    # train_gf = cudf.read_csv(DATA_PATH + 'test.csv')\n",
    "    \n",
    "print('train shape is', train.shape )\n",
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text embeddings shape (34250, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "model = TfidfVectorizer(stop_words=None, binary=True, max_features=5000)\n",
    "text_embeddings = model.fit_transform(train.title).toarray()\n",
    "print('text embeddings shape',text_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = torch.from_numpy(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = torch.matmul(text_embeddings, text_embeddings.T).T\n",
    "cts = cts.data.cpu().numpy()\n",
    "print(cts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = len(train)\n",
    "preds = []\n",
    "for k in range(ln):\n",
    "    # IDX = np.where(cts[k,]>0.7)[0]\n",
    "    IDX = np.where(cts[k,]>0.7)[0]\n",
    "    o = train.iloc[IDX].posting_id.values\n",
    "    preds.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for baseline = 0.6081278547251839\n"
     ]
    }
   ],
   "source": [
    "train['oof_text'] = preds\n",
    "\n",
    "if COMPUTE_CV:\n",
    "    train['f1'] = train.apply(getMetric('oof_text'),axis=1)\n",
    "    print('CV score for baseline =',train.f1.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-ecommerce-duplicates",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
