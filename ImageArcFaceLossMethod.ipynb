{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPuc9Z-Sp5Bo"
      },
      "source": [
        "# Image Arcface Loss Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21YP2cK2z8W0"
      },
      "source": [
        "## Mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-tMLOl7SRrm",
        "outputId": "be2654f2-c14e-4465-c32d-dd75cb1a8aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/dl-ecommerce-duplicates\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/dl-ecommerce-duplicates/\n",
        "!mkdir /content/data/\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/shopee-product-matching.zip /content/data/shopee-product-matching.zip\n",
        "!unzip -q /content/data/shopee-product-matching.zip -d /content/data/shopee-product-matching\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/dl-ecommerce-duplicates/data/train80.csv /content/data/shopee-product-matching/train80.csv\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/dl-ecommerce-duplicates/data/valid20.csv /content/data/shopee-product-matching/valid20.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6uAM3Ywp5Bu"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUNtGpJkqUvZ",
        "outputId": "f06471af-2750-47fa-dae1-c3639f98f053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m993.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.1 timm-0.6.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-2.4.0-cp310-cp310-manylinux2014_x86_64.whl (58.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (23.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.12.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.0.5)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (6.0)\n",
            "Collecting aiosignal (from ray[tune])\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist (from ray[tune])\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.27.1)\n",
            "Collecting virtualenv<20.21.1,>=20.0.24 (from ray[tune])\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (23.1)\n",
            "Collecting grpcio<=1.51.3,>=1.42.0 (from ray[tune])\n",
            "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.5.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (0.8.10)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.6 (from virtualenv<20.21.1,>=20.0.24->ray[tune])\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.10/dist-packages (from virtualenv<20.21.1,>=20.0.24->ray[tune]) (3.3.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ray[tune]) (1.16.0)\n",
            "Installing collected packages: distlib, virtualenv, tensorboardX, grpcio, frozenlist, aiosignal, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.54.0\n",
            "    Uninstalling grpcio-1.54.0:\n",
            "      Successfully uninstalled grpcio-1.54.0\n",
            "Successfully installed aiosignal-1.3.1 distlib-0.3.6 frozenlist-1.3.3 grpcio-1.51.3 ray-2.4.0 tensorboardX-2.6 virtualenv-20.21.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.28.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libomp-10-dev libomp5-10\n",
            "Suggested packages:\n",
            "  libomp-10-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-10-dev libomp-dev libomp5-10\n",
            "0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 351 kB of archives.\n",
            "After this operation, 2,281 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libomp5-10 amd64 1:10.0.0-4ubuntu1 [300 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libomp-10-dev amd64 1:10.0.0-4ubuntu1 [47.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libomp-dev amd64 1:10.0-50~exp1 [2,824 B]\n",
            "Fetched 351 kB in 1s (413 kB/s)\n",
            "Selecting previously unselected package libomp5-10:amd64.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5-10_1%3a10.0.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking libomp5-10:amd64 (1:10.0.0-4ubuntu1) ...\n",
            "Selecting previously unselected package libomp-10-dev.\n",
            "Preparing to unpack .../libomp-10-dev_1%3a10.0.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking libomp-10-dev (1:10.0.0-4ubuntu1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_1%3a10.0-50~exp1_amd64.deb ...\n",
            "Unpacking libomp-dev (1:10.0-50~exp1) ...\n",
            "Setting up libomp5-10:amd64 (1:10.0.0-4ubuntu1) ...\n",
            "Setting up libomp-10-dev (1:10.0.0-4ubuntu1) ...\n",
            "Setting up libomp-dev (1:10.0-50~exp1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu==1.7.2\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "!pip install ray[tune]\n",
        "!pip install transformers\n",
        "!apt install libomp-dev\n",
        "!python -m pip install --upgrade faiss-gpu==1.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqS_nrUJSrEk",
        "outputId": "e30eebff-55d1-420a-af73-b14698a92a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from warnings import filterwarnings\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "from modules.datasets.ImageArcFaceLossShopeeDataset import ImageArcFaceLossShopeeDataset\n",
        "from modules.losses.ArcFaceLoss import ArcFaceLoss\n",
        "from modules.models.ImageShopeeNet import ImageShopeeNet\n",
        "from modules.distances.CosineDistance import CosineDistance\n",
        "\n",
        "import modules.utils.dataset_utils as dataset_utils\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"You are using device: %s\" % device)\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "DATA_FOLDER = '/content/data/shopee-product-matching/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O10OKb9p5Bw"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppIIA7GNp5Bw",
        "outputId": "4398c5a6-01cb-4039-9e5a-2f1dc81d8e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All shape (34250, 7)\n",
            "Train shape (27399, 7)\n",
            "Valid shape (6851, 7)\n"
          ]
        }
      ],
      "source": [
        "DATA_FOLDER = '/content/data/shopee-product-matching/'\n",
        "\n",
        "train_df = dataset_utils.get_dataset(DATA_FOLDER, is_test=False, file_name='train80.csv')\n",
        "train_df = dataset_utils.add_target(train_df)\n",
        "\n",
        "valid_df = dataset_utils.get_dataset(DATA_FOLDER, is_test=False, file_name='valid20.csv')\n",
        "valid_df = dataset_utils.add_target(valid_df)\n",
        "\n",
        "all_df = train_df.append(valid_df, ignore_index=True)\n",
        "\n",
        "print(f\"All shape {all_df.shape}\")\n",
        "print(f\"Train shape {train_df.shape}\")\n",
        "print(f\"Valid shape {valid_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvKS58ZKp5Bx"
      },
      "source": [
        "## Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Id8kV1Oip5Bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1656ae8-20d0-463e-a8cb-a93c7d796a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27399\n",
            "6851\n"
          ]
        }
      ],
      "source": [
        "image_size = 512\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "\ttransforms.Resize((image_size, image_size)),\n",
        "\ttransforms.RandomPosterize(bits=2, p=0.3),\n",
        "\ttransforms.RandomHorizontalFlip(p=0.4),\n",
        "\ttransforms.RandomAutocontrast(p=0.3),\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "valid_transforms = transforms.Compose([\n",
        "\ttransforms.Resize((image_size, image_size)),\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = ImageArcFaceLossShopeeDataset(\n",
        "\ttrain_df['image'].values, \n",
        "\ttrain_df['label_group'].values,\n",
        "\ttrain_transforms\n",
        ")\n",
        "valid_dataset = ImageArcFaceLossShopeeDataset(\n",
        "\tvalid_df['image'].values, \n",
        "\tvalid_df['label_group'].values, \n",
        "\tvalid_transforms\n",
        ")\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(valid_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CFG"
      ],
      "metadata": {
        "id": "mWm5N-pJY7Na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    IMG_SZ = 512\n",
        "    TRAIN_RATIO = 0.8\n",
        "    EPOCHS = 10\n",
        "    MARGIN = 0.75\n",
        "    DISTANCE = CosineDistance()\n",
        "    image_size = 512\n",
        "    batch_size = 16\n",
        "    n_worker = 4\n",
        "    init_lr = 3e-4\n",
        "    dropout = 0.5\n",
        "    n_epochs = 30\n",
        "    n_splits = 5\n",
        "    n_samples = None\n",
        "    fold_id = 0\n",
        "    valid_every = 1\n",
        "    save_after = 0\n",
        "    scale = 10\n",
        "    margin = 0.5\n",
        "    easy_margin = False\n",
        "    search_space = np.arange(40, 100, 10)\n",
        "    debug = False\n",
        "    kernel_type = 'baseline'\n",
        "    model_dir = './weights/'\n",
        "    data_dir = './data/train_images'\n",
        "    csv = './data/train.csv'\n",
        "    n_classes = 11014\n"
      ],
      "metadata": {
        "id": "CDUWZOK2Y6M2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QvRUifgp5Bz"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(config):\n",
        "    return ImageShopeeNet(\n",
        "\t\tmodel_name=config[\"model_name\"],\n",
        "\t\tfc_dim=config[\"fc_dim\"],\n",
        "\t\tfreeze_layers=config[\"freeze_layers\"], \n",
        "\t\tdropout=config[\"dropout\"]\n",
        "\t)"
      ],
      "metadata": {
        "id": "r5J8liFXa6Hy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet18"
      ],
      "metadata": {
        "id": "BgvHjIh_0fTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "\t\"model_name\": \"resnet18\", \n",
        "\t\"fc_dim\": 512,\n",
        "\t\"freeze_layers\": False,\n",
        "\t\"dropout\": 0.5,\n",
        "\t\"lr\": 3e-4,\n",
        "\t\"batch_size\": 16\n",
        "}"
      ],
      "metadata": {
        "id": "lxaaMXOHteJb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(config).to(device)\n",
        "criterion = ArcFaceLoss(CFG.image_size, CFG.n_classes, s=CFG.scale, m=CFG.margin, easy_margin=CFG.easy_margin).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "\n",
        "# Datasets and data loaders\n",
        "training_sampler = torch.utils.data.SubsetRandomSampler(\n",
        "    torch.arange(len(train_dataset))[:int(0.4*len(train_dataset))]\n",
        ")\n",
        "valid_sampler = torch.utils.data.SubsetRandomSampler(\n",
        "    torch.arange(len(valid_dataset))[:int(0.4*len(valid_dataset))]\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    sampler=training_sampler,\n",
        "    batch_size=int(config[\"batch_size\"]),\n",
        "    # shuffle=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=int(config[\"batch_size\"]),\n",
        "    # shuffle=True,\n",
        "    sampler=valid_sampler,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "## Training loop: training + validation\n",
        "for epoch in range(10):\n",
        "    ## Training\n",
        "    train_loss = 0.0\n",
        "    epoch_steps = 0\n",
        "    model.train()\n",
        "    train_enumerator = enumerate(train_loader, 0)\n",
        "    train_enumerator = tqdm(train_enumerator)\n",
        "    for i, data in train_enumerator:\n",
        "        input, target = data\n",
        "        input, target = input.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        epoch_steps += 1\n",
        "        if i % 50 == 0:\n",
        "            print(\"[%d, %5d / %d batches] loss: %.3f\" % (epoch + 1, i + 1, len(train_loader),\n",
        "                                            train_loss / epoch_steps))\n",
        "    \n",
        "\n",
        "    ## Validation\n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    valid_enumerator = enumerate(valid_loader, 0)\n",
        "    valid_enumerator = tqdm(valid_enumerator)\n",
        "    for i, data in valid_enumerator:\n",
        "        with torch.no_grad():\n",
        "            input, target = data\n",
        "            input, target = input.to(device), target.to(device)\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "            val_loss += loss.cpu().numpy()\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(val_loss)"
      ],
      "metadata": {
        "id": "KL19w0pisJgS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "d5ab8e54-cad9-479e-a259-c4d952a788ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2e90caa447e4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArcFaceLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0measy_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0measy_margin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet121"
      ],
      "metadata": {
        "id": "3BST9QAfqGPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "\t\"model_name\": \"densenet121\", \n",
        "\t\"fc_dim\": train_df.label_group.nunique(),\n",
        "\t\"freeze_layers\": False,\n",
        "\t\"dropout\": 0.5,\n",
        "\t\"lr\": 3e-4,\n",
        "\t\"batch_size\": 16\n",
        "}"
      ],
      "metadata": {
        "id": "lwZpQzl70t8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(config).to(device)\n",
        "criterion = ArcFaceLoss(CFG.image_size, train_df.label_group.nunique(), s=CFG.scale, m=CFG.margin, easy_margin=CFG.easy_margin).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "\n",
        "# Datasets and data loaders\n",
        "training_sampler = torch.utils.data.SubsetRandomSampler(\n",
        "    torch.arange(len(train_dataset))[:int(0.4*len(train_dataset))]\n",
        ")\n",
        "valid_sampler = torch.utils.data.SubsetRandomSampler(\n",
        "    torch.arange(len(valid_dataset))[:int(0.4*len(valid_dataset))]\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    sampler=training_sampler,\n",
        "    batch_size=int(config[\"batch_size\"]),\n",
        "    # shuffle=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=int(config[\"batch_size\"]),\n",
        "    # shuffle=True,\n",
        "    sampler=valid_sampler,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "## Training loop: training + validation\n",
        "for epoch in range(10):\n",
        "    ## Training\n",
        "    train_loss = 0.0\n",
        "    epoch_steps = 0\n",
        "    model.train()\n",
        "    train_enumerator = enumerate(train_loader, 0)\n",
        "    train_enumerator = tqdm(train_enumerator)\n",
        "    for i, data in train_enumerator:\n",
        "        input, target = data\n",
        "        input, target = input.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        epoch_steps += 1\n",
        "        if i % 50 == 0:\n",
        "            print(\"[%d, %5d / %d batches] loss: %.3f\" % (epoch + 1, i + 1, len(train_loader),\n",
        "                                            train_loss / epoch_steps))\n",
        "    \n",
        "\n",
        "    ## Validation\n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    valid_enumerator = enumerate(valid_loader, 0)\n",
        "    valid_enumerator = tqdm(valid_enumerator)\n",
        "    for i, data in valid_enumerator:\n",
        "        with torch.no_grad():\n",
        "            input, target = data\n",
        "            input, target = input.to(device), target.to(device)\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "            val_loss += loss.cpu().numpy()\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(val_loss)"
      ],
      "metadata": {
        "id": "cFdhIYdB15hj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "21YP2cK2z8W0",
        "g6uAM3Ywp5Bu",
        "-O10OKb9p5Bw",
        "qvKS58ZKp5Bx",
        "mWm5N-pJY7Na",
        "3BST9QAfqGPv"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}